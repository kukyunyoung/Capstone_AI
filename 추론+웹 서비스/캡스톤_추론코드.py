# -*- coding: utf-8 -*-
"""캡스톤_추론코드 (1).ipynb의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TfDeffcFrfwFz3baeAq3f6tLVxQUmb9B
"""

!pip install tensorflow-addons
!pip install transformers

import os
import pandas as pd
import numpy as np
import re
from tqdm import tqdm
import urllib.request
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
import tensorflow as tf

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from transformers import BertTokenizer, TFBertForSequenceClassification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, log_loss

# 크롤링
import openpyxl
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from oauth2client.tools import argparser

from google.colab import drive

drive.mount('/content/drive', force_remount=True)

filepath = '/content/drive/My Drive/' + 'Colab Notebooks/'

# 크롤링 함수

def get_comments(video_id):
    comments = []
    next_page_token = None
    DEVELOPER_KEY = "AIzaSyBw9QZ4QkAQeElEiLD5cl0-CC_qfQTc85c"
    YOUTUBE_API_SERVICE_NAME = "youtube"
    YOUTUBE_API_VERSION = "v3"
    try:
        youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)

        # 댓글 목록 가져오기
        while True:
            results = youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                textFormat="plainText",
                maxResults=100,
                pageToken=next_page_token
            ).execute()

            # 댓글 텍스트 추출
            for item in results["items"]:
                comment = item["snippet"]["topLevelComment"]["snippet"]["textDisplay"]
                comments.append(comment)

            # 다음 페이지 토큰 가져오기
            next_page_token = results.get("nextPageToken")
            if not next_page_token:
                break

            # 최대 500개의 댓글만 가져오기
            if len(comments) >= 1000:
                break

    except HttpError as error:
        print(f"An HTTP error {error.resp.status} occurred: {error.content}")

    # 댓글 데이터 엑셀 파일로 저장
    wb = openpyxl.Workbook()
    sheet = wb.active
    sheet.title = "Comments"
    # 첫번째 행에 'comment', 'value' 추가
    sheet.cell(row=1, column=1, value="comment")
    sheet.cell(row=1, column=2, value='value')

    for i in range(len(comments)):
        sheet.cell(row=i+2, column=1, value=comments[i])
        sheet.cell(row=i+2, column=2, value=1)
    wb.save(filepath + "youtube_comments.xlsx")

    return comments

MODEL_NAME = "klue/bert-base"
tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)

BEST_MODEL_NAME = filepath + 'model/best_model.h5'
print(BEST_MODEL_NAME)

model = tf.keras.models.load_model(BEST_MODEL_NAME,
                                   custom_objects={'TFBertForSequenceClassification': TFBertForSequenceClassification},
                                   compile=False)

# 입력 데이터(문장) 길이 제한
MAX_SEQ_LEN = 64

def convert_data(X_data, y_data):
    # BERT 입력으로 들어가는 token, mask, segment, target 저장용 리스트
    tokens, masks, segments, targets = [], [], [], []

    for X, y in tqdm(zip(X_data, y_data)):
        # token: 입력 문장 토큰화
        token = tokenizer.encode(X, truncation = True, padding = 'max_length', max_length = MAX_SEQ_LEN)

        # Mask: 토큰화한 문장 내 패딩이 아닌 경우 1, 패딩인 경우 0으로 초기화
        num_zeros = token.count(0)
        mask = [1] * (MAX_SEQ_LEN - num_zeros) + [0] * num_zeros

        # segment: 문장 전후관계 구분: 오직 한 문장이므로 모두 0으로 초기화
        segment = [0]*MAX_SEQ_LEN

        tokens.append(token)
        masks.append(mask)
        segments.append(segment)
        targets.append(y)

    # numpy array로 저장
    tokens = np.array(tokens)
    masks = np.array(masks)
    segments = np.array(segments)
    targets = np.array(targets)

    return [tokens, masks, segments], targets

def comment_ratio(predicted_label):
  neg, pos, dontmind = 0, 0, 0

  for i in range(len(predicted_label)):
    if(predicted_label[i]==0):
      neg += 1
    if(predicted_label[i]==1):
      pos += 1
    if(predicted_label[i]==2):
      dontmind += 1

  pos_ratio = pos/len(predicted_label)
  neg_ratio = neg/len(predicted_label)
  dmd_ratio = dontmind/len(predicted_label)


  print('긍정:',pos_ratio, ', 부정:',neg_ratio, ',관련없음:',dmd_ratio)
  return pos_ratio, neg_ratio, dmd_ratio

def cmt_list(predicted_label, x_data):
  zero = 0
  one = 0
  cmt_neg = []
  cmt_pos = []

  for i, label in enumerate(predicted_label):
      if label == 0:
        if(zero>=8):
          break
        cmt_neg.append(x_data[i])
        zero += 1

  for i, label in enumerate(predicted_label):
      if label == 1:
        if(one>=8):
          break
        cmt_pos.append(x_data[i])
        one += 1

  return cmt_pos, cmt_neg

# 웹페이지 주
from google.colab.output import eval_js
print(eval_js("google.colab.kernel.proxyPort(5000)"))

#flask

from flask import Flask, request, render_template
app = Flask(__name__, template_folder='/content/drive/MyDrive/templates')

@app.route("/")
def index():
    return render_template('index.html')

@app.route("/resultPage", methods=['POST'])
def resultPage():
  input = [str(x) for x in request.form.values()]
  input = ''.join(input)
  print('input : ', input, ", type : ", type(input))
  get_comments(input)
  cmt = pd.read_excel(filepath + 'youtube_comments.xlsx')

  # BEST_MODEL_NAME = filepath + 'model/best_model.h5'
  # print(BEST_MODEL_NAME)

  model = tf.keras.models.load_model(BEST_MODEL_NAME,
                                     custom_objects={'TFBertForSequenceClassification': TFBertForSequenceClassification},
                                     compile=False)
  print('전처리 전 댓글들의 개수 :', len(cmt))

  # comment 열의 중복 제거
  cmt.drop_duplicates(subset=['comment'], inplace=True)
  # null값이 존재하는 행 제거
  cmt = cmt.dropna(how='any')
  # 한글과 공백을 제외하고 모두 제거
  cmt['comment'] = cmt['comment'].str.replace("[^ㄱ-ㅎㅏ-ㅣ가-힣 ]","")

  print('전처리 후 훈련용 샘플의 개수 :',len(cmt))

  print(cmt.shape)

  x_data = cmt['comment']
  y_data = cmt['value']

  comment, trash = convert_data(x_data, y_data)

  predicted_value = model.predict(comment)
  predicted_label = np.argmax(predicted_value, axis = 1)

  pos_ratio, neg_ratio, dmd_ratio = comment_ratio(predicted_label)

  posi, nega = cmt_list(predicted_label, x_data)
  print('긍정')
  print(*posi, sep='\n')
  print('\n부정')
  print(*nega, sep='\n')


  return render_template('resultPage.html', output = input, positive=pos_ratio, negative=neg_ratio,Irrelevant=dmd_ratio, comments=nega)


app.run()